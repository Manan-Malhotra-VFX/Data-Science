{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost_LGBM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcJT7I1vwK53",
        "outputId": "aa41185f-18d8-4ea1-87f3-afd70b18e3b5"
      },
      "source": [
        "pip install lightgbm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gclJLbCHwLgi"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6lLhmcnwLi6",
        "outputId": "6a392c04-b415-418d-b626-c7bf54322de9"
      },
      "source": [
        "cancer_data =load_breast_cancer()\n",
        "cancer_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
              " 'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/breast_cancer.csv',\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9')}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQ04bqPwLlv"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "DgxTZNd-wLoY",
        "outputId": "b4c1f3cf-3485-4a09-98ae-3b91ec13dc87"
      },
      "source": [
        "import pandas as pd\n",
        "X = cancer_data.data\n",
        "y = cancer_data.target\n",
        "cancer_data = pd.DataFrame(X,columns = cancer_data.feature_names)\n",
        "\n",
        "cancer_data['TARGET'] = y\n",
        "cancer_data.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.01382</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.01039</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.03029</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.01448</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.03502</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.01226</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.07217</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.01432</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  TARGET\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "3        11.42         20.38  ...                  0.17300       0\n",
              "4        20.29         14.34  ...                  0.07678       0\n",
              "5        12.45         15.70  ...                  0.12440       0\n",
              "6        18.25         19.98  ...                  0.08368       0\n",
              "7        13.71         20.83  ...                  0.11510       0\n",
              "8        13.00         21.82  ...                  0.10720       0\n",
              "9        12.46         24.04  ...                  0.20750       0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOj1H8f9wLq8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lUWTqPHwLup",
        "outputId": "4224e5a4-1455-4643-b839-2689ef86d3b3"
      },
      "source": [
        "####### Replace categorical values with numbers########\n",
        "cancer_data['TARGET'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: TARGET, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "KdRKELyqwLxe",
        "outputId": "b7bebaad-a4d3-46a7-8337-2cb44cb116bb"
      },
      "source": [
        "X = cancer_data.drop(['TARGET'],axis=1)\n",
        "X"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7q0osTmhwLz4",
        "outputId": "d096c967-869a-43ee-b09c-7925c4622341"
      },
      "source": [
        "y = cancer_data[['TARGET']]\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     TARGET\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "..      ...\n",
              "564       0\n",
              "565       0\n",
              "566       0\n",
              "567       0\n",
              "568       1\n",
              "\n",
              "[569 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmCABUHVwL2m",
        "outputId": "b54519f6-700e-46ec-dfb4-917d171f3a98"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "X"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
              "         2.75062224,  1.93701461],\n",
              "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
              "        -0.24388967,  0.28118999],\n",
              "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
              "         1.152255  ,  0.20139121],\n",
              "       ...,\n",
              "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
              "        -1.10454895, -0.31840916],\n",
              "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
              "         1.91908301,  2.21963528],\n",
              "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
              "        -0.04813821, -0.75120669]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JRKQ1pdwL5D"
      },
      "source": [
        "##Split data into train and test to verify accuracy after fitting the model. \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX_SZtBEwL77"
      },
      "source": [
        "import lightgbm as lgb\n",
        "d_train = lgb.Dataset(X_train, label=y_train)\n",
        "\n",
        "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "lgbm_params = {'learning_rate':0.05, \n",
        "               'boosting_type':'dart',    #Try dart for better accuracy #gbdt\n",
        "               'objective':'binary',\n",
        "               'metric':['auc', 'binary_logloss'],\n",
        "               'num_leaves':100,\n",
        "               'max_depth':10}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd7775anwL-g",
        "outputId": "428b134e-beee-437e-bfb6-15c71076bd5f"
      },
      "source": [
        "start=datetime.now()\n",
        "clf = lgb.train(lgbm_params, d_train, 50) #50 iterations. Increase iterations for small learning rates\n",
        "stop=datetime.now()\n",
        "execution_time_lgbm = stop-start\n",
        "print(\"LGBM execution time is: \", execution_time_lgbm)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LGBM execution time is:  0:00:00.189613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27yYCkDMzOKi",
        "outputId": "8c4e72e2-36ab-4b4c-83f2-e80398c3a206"
      },
      "source": [
        "#Prediction on test data\n",
        "y_pred_lgbm=clf.predict(X_test)\n",
        "y_pred_lgbm"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.90498815, 0.13873902, 0.12587612, 0.91240406, 0.91575657,\n",
              "       0.13581893, 0.13469091, 0.30932181, 0.60601362, 0.89579044,\n",
              "       0.88276975, 0.15165972, 0.89881436, 0.575407  , 0.91326252,\n",
              "       0.13172936, 0.91254069, 0.91217391, 0.91262018, 0.13420232,\n",
              "       0.86006433, 0.89679125, 0.13180189, 0.91588627, 0.88273681,\n",
              "       0.86713137, 0.917053  , 0.86643142, 0.915501  , 0.12700631,\n",
              "       0.90733794, 0.91416867, 0.83487816, 0.90983787, 0.91538674,\n",
              "       0.90935416, 0.45523684, 0.83027026, 0.12992499, 0.73244467,\n",
              "       0.91553107, 0.12476009, 0.9225189 , 0.9154202 , 0.80489044,\n",
              "       0.8950209 , 0.90446943, 0.88496159, 0.8954793 , 0.91404408,\n",
              "       0.12979935, 0.13182853, 0.8342085 , 0.82288373, 0.916278  ,\n",
              "       0.89640664, 0.91613157, 0.13153318, 0.19540361, 0.90689331,\n",
              "       0.91542823, 0.13170531, 0.13216027, 0.84523026, 0.91632601,\n",
              "       0.8600245 , 0.12894201, 0.13569606, 0.9128334 , 0.90101178,\n",
              "       0.14422347, 0.13020051, 0.89719812, 0.14589826, 0.88273681,\n",
              "       0.84676379, 0.88320107, 0.76230261, 0.91540812, 0.85162016,\n",
              "       0.18116941, 0.91545469, 0.67344319, 0.13682006, 0.32672073,\n",
              "       0.13057844, 0.30248742, 0.1331478 , 0.88502075, 0.91807213,\n",
              "       0.91122957, 0.78315147, 0.81882851, 0.8853235 , 0.90857748,\n",
              "       0.91605204, 0.1347616 , 0.12666254, 0.91419044, 0.13591771,\n",
              "       0.29320679, 0.91483313, 0.20665221, 0.13196104, 0.83994505,\n",
              "       0.90876137, 0.90971389, 0.12828362, 0.53139879, 0.89660665,\n",
              "       0.1241106 , 0.90702268, 0.74685527, 0.13442063])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyicLYAHzTu2"
      },
      "source": [
        "#convert into binary values 0/1 for classification\n",
        "for i in range(0, X_test.shape[0]):\n",
        "    if y_pred_lgbm[i]>=.5:       # setting threshold to .5\n",
        "       y_pred_lgbm[i]=1\n",
        "    else:  \n",
        "       y_pred_lgbm[i]=0"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgUi5XLWzXMm",
        "outputId": "b938debd-bbca-440f-f080-b9a7c80a9bf5"
      },
      "source": [
        "#Print accuracy\n",
        "print (\"Accuracy with LGBM = \", metrics.accuracy_score(y_pred_lgbm,y_test))\n",
        "\n",
        "#GBDT - 95.6140\n",
        "#DART - 96.50"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with LGBM =  0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "biWZ0DJxzaTm",
        "outputId": "811fb230-2fb8-4652-bcc8-1a429dce52bf"
      },
      "source": [
        "#Confusion matrix\n",
        "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
        "sns.heatmap(cm_lgbm, annot=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5ce6083ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG0cjvb_zc4Q",
        "outputId": "643d49f2-dd4b-49bb-8c7e-c1eefd26c71d"
      },
      "source": [
        "print(\"AUC score with LGBM is: \", roc_auc_score(y_pred_lgbm,y_test))\n",
        "#AUC with GBDT - 96.04\n",
        "#AUC with DART - 97.33"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score with LGBM is:  0.9733333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP8maG1hzjxZ"
      },
      "source": [
        "## **XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pkTxx-pzndn"
      },
      "source": [
        "import xgboost as xgb \n",
        "dtrain=xgb.DMatrix(X_train,label=y_train)\n",
        "\n",
        "\n",
        "#setting parameters for xgboost\n",
        "parameters={'max_depth':10, \n",
        "            'objective':'binary:logistic',\n",
        "            'eval_metric':'auc',\n",
        "            'learning_rate':.05,\n",
        "             'ntree_limit':'num_round'}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVE9k0vmzsmn"
      },
      "source": [
        "start = datetime.now() \n",
        "xg=xgb.train(parameters, dtrain, 50,) \n",
        "stop = datetime.now()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVOCX2zzuoX",
        "outputId": "395694da-1401-47d8-fbbb-50eb983ed7d2"
      },
      "source": [
        "#Execution time of the model \n",
        "execution_time_xgb = stop-start \n",
        "print(\"XGBoost execution time is: \", execution_time_xgb)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBoost execution time is:  0:00:00.085592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvtVEhuJzw9i",
        "outputId": "e98cf73f-ef61-490f-995b-7540bdcd7421"
      },
      "source": [
        "#now predicting the model on the test set \n",
        "dtest=xgb.DMatrix(X_test)\n",
        "y_pred_xgb = xg.predict(dtest) \n",
        "y_pred_xgb"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.95560884, 0.04670651, 0.04670651, 0.9537023 , 0.95624447,\n",
              "       0.04670651, 0.04670651, 0.1603016 , 0.36296606, 0.9305706 ,\n",
              "       0.90305775, 0.05922021, 0.93202883, 0.35635746, 0.9545101 ,\n",
              "       0.0576926 , 0.952365  , 0.9525279 , 0.95624447, 0.04670651,\n",
              "       0.9241578 , 0.95624447, 0.04670651, 0.95624447, 0.94778883,\n",
              "       0.90283585, 0.95560884, 0.90431106, 0.95624447, 0.04670651,\n",
              "       0.9522422 , 0.95624447, 0.75554246, 0.95344365, 0.95624447,\n",
              "       0.95624447, 0.21091998, 0.9526681 , 0.04670651, 0.8953967 ,\n",
              "       0.95624447, 0.04670651, 0.9537023 , 0.95624447, 0.7994155 ,\n",
              "       0.9486641 , 0.9512375 , 0.9073691 , 0.95560884, 0.95383966,\n",
              "       0.04670651, 0.04670651, 0.9148721 , 0.87775636, 0.95624447,\n",
              "       0.95624447, 0.95624447, 0.04670651, 0.13902105, 0.95624447,\n",
              "       0.95624447, 0.04670651, 0.04670651, 0.8815996 , 0.95624447,\n",
              "       0.93171215, 0.04670651, 0.0586894 , 0.95624447, 0.95560884,\n",
              "       0.05679741, 0.04670651, 0.9545101 , 0.04670651, 0.94778883,\n",
              "       0.926143  , 0.9380006 , 0.8494658 , 0.95624447, 0.9035584 ,\n",
              "       0.05971391, 0.95624447, 0.8965802 , 0.04887486, 0.16184074,\n",
              "       0.04902546, 0.13833581, 0.05271521, 0.9507049 , 0.9554888 ,\n",
              "       0.9537023 , 0.9233619 , 0.88021064, 0.9066809 , 0.95624447,\n",
              "       0.95624447, 0.04670651, 0.04670651, 0.95624447, 0.04910145,\n",
              "       0.04984578, 0.95624447, 0.07137172, 0.04670651, 0.94778883,\n",
              "       0.95624447, 0.9476782 , 0.04670651, 0.43999705, 0.9080657 ,\n",
              "       0.04670651, 0.95624447, 0.7159188 , 0.04670651], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azie0S46z2X8"
      },
      "source": [
        "#Converting probabilities into 1 or 0  \n",
        "for i in range(0, X_test.shape[0]): \n",
        "    if y_pred_xgb[i]>=.5:       # setting threshold to .5 \n",
        "       y_pred_xgb[i]=1 \n",
        "    else: \n",
        "       y_pred_xgb[i]=0  "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "SMbgu07_z4s-",
        "outputId": "a8a96e99-98a9-4094-fd4d-04d7445488fd"
      },
      "source": [
        "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "sns.heatmap(cm_xgb, annot=True)\n",
        "\n",
        "print (\"Accuracy with XGBoost= \", metrics.accuracy_score(y_pred_xgb, y_test))\n",
        "print(\"AUC score with XGBoost is: \", roc_auc_score(y_pred_xgb, y_test))\n",
        "\n",
        "#Without 'ntree_limit=num_round' --> Accuracy --> 95.61, AUC --> 95.53\n",
        "#With 'ntree_limit=num_round'    --> Accuracy --> 95.61, AUC --> 95.53"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy with XGBoost=  0.956140350877193\n",
            "AUC score with XGBoost is:  0.9553571428571429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6xCGdQ_0AQa",
        "outputId": "5e6d4cbc-f43c-47c9-8574-3317680c8262"
      },
      "source": [
        "################\n",
        "#SUMMARY\n",
        "print(\"################################################\")\n",
        "print(\"LGBM execution time is: \", execution_time_lgbm)\n",
        "print(\"XGBoost execution time is: \", execution_time_xgb)\n",
        "print(\"################################################\")\n",
        "print (\"Accuracy with LGBM = \", metrics.accuracy_score(y_pred_lgbm,y_test))\n",
        "print (\"Accuracy with XGBoost= \", metrics.accuracy_score(y_pred_xgb, y_test))\n",
        "print(\"################################################\")\n",
        "print(\"AUC score with LGBM is: \", roc_auc_score(y_pred_lgbm,y_test))\n",
        "print(\"AUC score with XGBoost is: \", roc_auc_score(y_pred_xgb, y_test))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################################################\n",
            "LGBM execution time is:  0:00:00.189613\n",
            "XGBoost execution time is:  0:00:00.085592\n",
            "################################################\n",
            "Accuracy with LGBM =  0.9649122807017544\n",
            "Accuracy with XGBoost=  0.956140350877193\n",
            "################################################\n",
            "AUC score with LGBM is:  0.9733333333333334\n",
            "AUC score with XGBoost is:  0.9553571428571429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-dTwbno0C-w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}